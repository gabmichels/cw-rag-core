{
  "name": "Zenithfall Obsidian RAG",
  "nodes": [
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "preview-check",
              "leftValue": "={{ $json.wouldPublish }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equal"
              }
            },
            {
              "id": "d7d4b571-802f-4d34-a984-aca35a930b19",
              "leftValue": "={{ $json.wouldPublish }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "or"
        },
        "options": {}
      },
      "name": "Check Preview Result",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -784,
        1216
      ],
      "id": "e4695326-6f7e-493f-9d7a-3b43d712e7a9",
      "notes": "Branch based on preview result"
    },
    {
      "parameters": {
        "jsCode": "// Log policy block for rejected documents\nconst previewResult = $json;\nconst filePath = $('Initialize Config & Extract Event1').first().json.filePath;\n\nconsole.log(`BLOCKED: Document rejected by policy`);\nconsole.log(`- File: ${filePath}`);\nconsole.log(`- Would publish: ${previewResult.wouldPublish}`);\nconsole.log(`- Findings: ${JSON.stringify(previewResult.findings)}`);\n\nreturn [{\n  status: 'blocked',\n  filePath,\n  findings: previewResult.findings || [],\n  timestamp: new Date().toISOString()\n}];"
      },
      "name": "Log Policy Block",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -576,
        1264
      ],
      "id": "2900fcab-2a3d-49b3-8836-c7510b89754a",
      "notes": "Log when document is blocked by policy"
    },
    {
      "parameters": {
        "jsCode": "// Zenithfall-specific configuration\nconst config = {\n  obsidianVaultPath: $env.OBSIDIAN_VAULT_PATH || '/vault/Zenithfall',\n  tenantId: 'zenithfall',\n  fileExtensions: ['.md', '.markdown'],\n  excludePaths: ['.obsidian', '.trash', 'templates', 'Archive'],\n  acl: ['public'],\n  source: 'obsidian',\n  lang: 'en',\n  apiUrl: ($env.ZENITHFALL_API_URL || 'http://api:3000').trim(),\n  ingestToken: ($env.ZENITHFALL_INGEST_TOKEN || 'missing-token').trim()\n};\n\n// Get file info from trigger\nconst triggerData = $input.first().json;\nconst filePath = triggerData.path;\nconst eventType = triggerData.event; // 'add', 'change', or 'unlink'\n\nconsole.log(`=== ZENITHFALL FILE EVENT ===`);\nconsole.log(`Event: ${eventType}`);\nconsole.log(`File: ${filePath}`);\nconsole.log(`API URL: '${config.apiUrl}'`);\nconsole.log(`Ingest token configured: ${config.ingestToken ? 'Yes' : 'No'}`);\n\nreturn [{\n  config,\n  filePath,\n  eventType,\n  timestamp: new Date().toISOString()\n}];"
      },
      "name": "Initialize Config & Extract Event1",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2176,
        1360
      ],
      "id": "4ed7d487-c609-4c4c-b32b-f8c77a5410e4",
      "notes": "Initialize config and extract file event details from trigger"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "unlink-check",
              "leftValue": "={{ $json.eventType }}",
              "rightValue": "unlink",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "or"
        },
        "options": {}
      },
      "name": "Check Event Type1",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -1984,
        1360
      ],
      "id": "183983e2-7090-4595-9cef-c9a55bdabb1f",
      "notes": "Branch based on event type\nTrue: File deleted (unlink), False: File added/changed"
    },
    {
      "parameters": {
        "fileSelector": "={{ $json.filePath }}",
        "options": {
          "dataPropertyName": "data"
        }
      },
      "name": "Read File Content1",
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -1856,
        1152
      ],
      "id": "2090fedb-7204-4468-8d09-086ab0a78b04",
      "notes": "Read the file content for processing"
    },
    {
      "parameters": {
        "jsCode": "// Parse markdown file and create normalized document\nconst path = require('path');\nconst filePath = $json.filePath;\nconst content = $json.fileContent;\nconst config = $json.config;\nconst fileHash = $json.fileHash;\n\ntry {\n  // Parse frontmatter\n  const frontmatterRegex = /^---\\s*\\n([\\s\\S]*?)\\n---\\s*\\n([\\s\\S]*)$/;\n  const match = content.match(frontmatterRegex);\n  \n  let frontmatter = {};\n  let markdownContent = content;\n  \n  if (match) {\n    try {\n      const yamlContent = match[1];\n      const lines = yamlContent.split('\\n');\n      \n      for (const line of lines) {\n        const colonIndex = line.indexOf(':');\n        if (colonIndex > 0) {\n          const key = line.substring(0, colonIndex).trim();\n          const value = line.substring(colonIndex + 1).trim();\n          \n          if (value.startsWith('[') && value.endsWith(']')) {\n            frontmatter[key] = value.slice(1, -1).split(',').map(s => s.trim().replace(/^\"|\"$/g, ''));\n          } else {\n            frontmatter[key] = value.replace(/^\"|\"$/g, '');\n          }\n        }\n      }\n      \n      markdownContent = match[2];\n    } catch (yamlError) {\n      console.log(`Failed to parse frontmatter for ${filePath}:`, yamlError.message);\n    }\n  }\n  \n  // Generate docId as vault-relative forward-slash path\n  const relativePath = path.relative(config.obsidianVaultPath, filePath);\n  const docId = relativePath.replace(/\\.(md|markdown)$/i, '').replace(/\\\\/g, '/');\n  \n  // Extract title\n  const title = frontmatter.title || \n                markdownContent.match(/^#\\s+(.+)$/m)?.[1] || \n                path.basename(filePath, path.extname(filePath));\n  \n  // Parse content into blocks\n  const blocks = [];\n  const sections = markdownContent.split(/\\n(?=#{1,6}\\s)/);\n  \n  for (const section of sections) {\n    const trimmed = section.trim();\n    if (trimmed) {\n      let blockType = 'text';\n      if (trimmed.includes('```')) {\n        blockType = 'code';\n      } else if (trimmed.includes('|') && trimmed.includes('---')) {\n        blockType = 'table';\n      }\n      \n      blocks.push({\n        type: blockType,\n        text: trimmed,\n        html: trimmed\n      });\n    }\n  }\n  \n  // Create NormalizedDoc\n  const normalizedDoc = {\n    meta: {\n      tenant: config.tenantId,\n      docId: docId,\n      source: config.source,\n      path: relativePath.replace(/\\\\/g, '/'),\n      title: title,\n      lang: config.lang,\n      version: frontmatter.version || '1.0',\n      sha256: fileHash,\n      acl: frontmatter.acl || frontmatter.tags || config.acl,\n      authors: frontmatter.authors || (frontmatter.author ? [frontmatter.author] : []),\n      tags: frontmatter.tags || [],\n      timestamp: new Date().toISOString(),\n      modifiedAt: new Date().toISOString(),\n      deleted: false\n    },\n    blocks: blocks\n  };\n  \n  console.log(`Parsed document: ${docId}`);\n  \n  return [normalizedDoc];\n  \n} catch (error) {\n  console.error(`Error parsing ${filePath}:`, error.message);\n  return [{\n    _error: true,\n    _filePath: filePath,\n    _errorMessage: error.message\n  }];\n}"
      },
      "name": "Parse Document1",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1136,
        1232
      ],
      "id": "785d7fc3-99c0-446b-b7c8-0f40d43f79ba",
      "notes": "Parse markdown file into normalized document format"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $('Initialize Config & Extract Event1').first().json.config.apiUrl + '/ingest/preview' }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "x-ingest-token",
              "value": "={{ $('Initialize Config & Extract Event1').first().json.config.ingestToken }}"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify([$json]) }}",
        "options": {
          "timeout": 30000
        }
      },
      "name": "Preview Document1",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        -976,
        1216
      ],
      "id": "44f754d1-7f5b-43e5-8461-05f0f795dd99",
      "notes": "Preview single document for PII policy compliance"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $('Initialize Config & Extract Event1').first().json.config.apiUrl + '/ingest/publish' }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "x-ingest-token",
              "value": "={{ $('Initialize Config & Extract Event1').first().json.config.ingestToken }}"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify([$('Parse Document1').first().json]) }}",
        "options": {
          "timeout": 60000
        }
      },
      "name": "Publish Document1",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        -576,
        1120
      ],
      "id": "93b9a82e-bcd7-4bbc-99c1-49f3d55e7550",
      "notes": "Publish approved document"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $('Initialize Config & Extract Event1').first().json.config.apiUrl + '/ingest/publish' }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "x-ingest-token",
              "value": "={{ $('Initialize Config & Extract Event1').first().json.config.ingestToken }}"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify([$json]) }}",
        "options": {
          "timeout": 30000
        }
      },
      "name": "Publish Tombstone1",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        -1584,
        1456
      ],
      "id": "7d8ff643-9c08-40da-925b-fa045777a324",
      "notes": "Publish tombstone for vector cleanup"
    },
    {
      "parameters": {
        "jsCode": "// Update workflow state and clean up file hashes\nconst staticData = $getWorkflowStaticData('global');\nconst fileHashes = staticData.fileHashes || {};\nconst initData = $('Initialize Config & Extract Event1').first().json;\nconst filePath = initData.filePath;\nconst eventType = initData.eventType;\n\nif (eventType === 'unlink') {\n  // Remove hash for deleted file\n  delete fileHashes[filePath];\n  console.log(`Removed hash for deleted file: ${filePath}`);\n} else {\n  console.log(`Updated hash for file: ${filePath}`);\n}\n\n// Update static data\nstaticData.fileHashes = fileHashes;\nstaticData.lastRunTime = new Date().toISOString();\n\nconsole.log(`Workflow completed for ${eventType} event on ${filePath}`);\n\nreturn [{\n  status: 'completed',\n  eventType,\n  filePath,\n  timestamp: new Date().toISOString()\n}];"
      },
      "name": "Update State1",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -336,
        1376
      ],
      "id": "ff6f3fcc-370c-48e2-bcf0-d858cabffaa6",
      "notes": "Update workflow state and clean up file tracking"
    },
    {
      "parameters": {
        "triggerOn": "folder",
        "path": "/vault/Zenithfall",
        "events": [
          "change",
          "add",
          "unlink"
        ],
        "options": {
          "usePolling": true
        }
      },
      "name": "Local File Trigger",
      "type": "n8n-nodes-base.localFileTrigger",
      "typeVersion": 1,
      "position": [
        -2400,
        1360
      ],
      "id": "745dd154-9570-4103-8706-942228124825",
      "notes": "Triggers on file changes in the specified local folder\nWatches for file creation, modification, and deletion"
    },
    {
      "parameters": {
        "operation": "text",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -1696,
        1152
      ],
      "id": "bcc0f0a3-4b3d-4233-842d-b51bf27686c4",
      "name": "Extract from File"
    },
    {
      "parameters": {
        "jsCode": "// Create tombstone for deleted file\nconst path = require('path');\nconst crypto = require('crypto');\n\n// Get data from Initialize Config & Extract Event node\nconst initData = $input.first().json;\nconst filePath = initData.filePath;\nconst config = initData.config;\n\nconst relativePath = path.relative(config.obsidianVaultPath, filePath);\nconst docId = relativePath.replace(/\\.(md|markdown)$/i, '').replace(/\\\\/g, '/');\n\nconsole.log(`Creating tombstone for deleted file: ${docId}`);\n\n// Generate proper SHA256 hash for tombstone (hash of deletion info)\nconst deletionContent = `DELETED:${config.tenantId}:${docId}:${new Date().toISOString()}`;\nconst sha256 = crypto.createHash('sha256').update(deletionContent).digest('hex');\n\nconst tombstone = {\n  meta: {\n    tenant: config.tenantId,\n    docId: docId,\n    source: config.source,\n    path: relativePath.replace(/\\\\/g, '/'),\n    title: `[DELETED] ${path.basename(filePath, path.extname(filePath))}`,\n    lang: config.lang,\n    version: '1.0',\n    sha256: sha256,\n    acl: ['system'],\n    authors: [],\n    tags: ['deleted', 'tombstone'],\n    timestamp: new Date().toISOString(),\n    modifiedAt: new Date().toISOString(),\n    deleted: true\n  },\n  blocks: []\n};\n\n// Clean up file hash from static data\nconst staticData = $getWorkflowStaticData('global');\nif (staticData.fileHashes && staticData.fileHashes[filePath]) {\n  delete staticData.fileHashes[filePath];\n  console.log(`Removed file hash for deleted file: ${filePath}`);\n}\n\nreturn [tombstone];"
      },
      "name": "Create Tombstone2",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1776,
        1456
      ],
      "id": "257934aa-343c-4185-a886-d9b8b48e8d81",
      "notes": "Create tombstone document for deleted file"
    },
    {
      "parameters": {
        "jsCode": "// Check if file should be processed and handle idempotency\n// Get data from previous nodes\nconst initData = $input.first().json;\nconst filePath = initData.filePath;\nconst config = initData.config;\nconst fileContent = initData.data; // File content from Read File Content node\nconst crypto = require('crypto');\nconst path = require('path');\n\nconsole.log(`Checking file: ${filePath}`);\nconsole.log(`File content length: ${fileContent ? fileContent.length : 'undefined'}`);\n\n// Filter out excluded paths\nif (config.excludePaths.some(excludePath => filePath.includes(`\\\\${excludePath}\\\\`))) {\n  console.log(`SKIP: ${filePath} (excluded path)`);\n  return [{ _skip: true, reason: 'excluded_path', filePath }];\n}\n\n// Check file extension\nconst ext = path.extname(filePath).toLowerCase();\nif (!config.fileExtensions.includes(ext)) {\n  console.log(`SKIP: ${filePath} (not markdown)`);\n  return [{ _skip: true, reason: 'not_markdown', filePath }];\n}\n\n// Calculate file hash for idempotency\nconst fileHash = crypto.createHash('sha256').update(fileContent).digest('hex');\n\n// Get previous hash from static data\nconst staticData = $getWorkflowStaticData('global');\nconst fileHashes = staticData.fileHashes || {};\nconst previousHash = fileHashes[filePath];\n\nif (previousHash && previousHash === fileHash) {\n  console.log(`SKIP: ${filePath} (unchanged)`);\n  return [{ _skip: true, reason: 'unchanged', filePath }];\n}\n\nconsole.log(`PROCESS: ${filePath} (${previousHash ? 'modified' : 'new'})`);\n\n// Update hash in static data\nfileHashes[filePath] = fileHash;\nstaticData.fileHashes = fileHashes;\n\nreturn [{\n  filePath,\n  fileContent,\n  fileHash,\n  isNew: !previousHash,\n  config,\n  timestamp: new Date().toISOString()\n}];"
      },
      "name": "Check File & Idempotency1",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1312,
        1216
      ],
      "id": "0dcde7e3-7a0d-4806-97ed-3b21586b8254",
      "notes": "Check if file should be processed and handle idempotency"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        -1504,
        1216
      ],
      "id": "24eccc62-8fbc-49c0-93a2-5b9d3c89e4f9",
      "name": "Merge"
    }
  ],
  "pinData": {},
  "connections": {
    "Check Preview Result": {
      "main": [
        [
          {
            "node": "Publish Document1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Log Policy Block",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Log Policy Block": {
      "main": [
        [
          {
            "node": "Update State1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Initialize Config & Extract Event1": {
      "main": [
        [
          {
            "node": "Check Event Type1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Event Type1": {
      "main": [
        [
          {
            "node": "Create Tombstone2",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Read File Content1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Read File Content1": {
      "main": [
        [
          {
            "node": "Extract from File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Document1": {
      "main": [
        [
          {
            "node": "Preview Document1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Preview Document1": {
      "main": [
        [
          {
            "node": "Check Preview Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Publish Document1": {
      "main": [
        [
          {
            "node": "Update State1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Publish Tombstone1": {
      "main": [
        [
          {
            "node": "Update State1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Local File Trigger": {
      "main": [
        [
          {
            "node": "Initialize Config & Extract Event1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Tombstone2": {
      "main": [
        [
          {
            "node": "Publish Tombstone1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check File & Idempotency1": {
      "main": [
        [
          {
            "node": "Parse Document1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Check File & Idempotency1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "fee1d9ce-f1db-4385-9543-86c0aa3a56be",
  "meta": {
    "instanceId": "560b438390dee1f3268219b2a8ca0b8d4e15ec412dd27c0fc3ee60cc31cb05bc"
  },
  "id": "MT1tHbTar4rQavpA",
  "tags": [
    {
      "createdAt": "2025-09-22T21:58:28.243Z",
      "updatedAt": "2025-09-22T21:58:28.243Z",
      "id": "RMcToQ0NhUjkJnqc",
      "name": "obsidian"
    },
    {
      "createdAt": "2025-09-22T21:58:28.272Z",
      "updatedAt": "2025-09-22T21:58:28.272Z",
      "id": "2dznyA0fVDxsVeR1",
      "name": "zenithfall"
    },
    {
      "createdAt": "2025-09-22T21:58:28.243Z",
      "updatedAt": "2025-09-22T21:58:28.243Z",
      "id": "2M6gxZTzgxgatZKE",
      "name": "ingestion"
    }
  ]
}